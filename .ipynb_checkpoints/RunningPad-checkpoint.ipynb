{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/home/bns332/anaconda3/envs/myenv/bin bash\n",
    "rm -r model\n",
    "rm -r val\n",
    "rm -r log\n",
    "mkdir model\n",
    "mkdir val\n",
    "mkdir log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"/home/bns332/foldingnet/train.txt\")\n",
    "a = os.listdir('/home/bns332/foldingnet/Complex_Buildings')\n",
    "fi = open(\"/home/bns332/foldingnet/train.txt\",\"a\")\n",
    "for files in a:\n",
    "    fi.write(files+\"\\n\") \n",
    "    #os.remove(\"/home/bns332/foldingnet/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/bns332/foldingnet/src')\n",
    "import pointnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import open3d\n",
    "from open3d import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/bns332/foldingnet/src')\n",
    "import foldingnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/bns332/foldingnet/src')\n",
    "import datasets\n",
    "from datasets import plyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catelog done !\n",
      "About to create model\n",
      "About to start training\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "'''\n",
    "train foldingnet on nyc data\n",
    "\n",
    "author  : Ruoyu Wang; Yuqiong Li\n",
    "created : 10/25/18 1:29 PM\n",
    "'''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from foldingnet import FoldingNetVanilla\n",
    "from foldingnet import ChamfersDistance\n",
    "from datasets import pcdDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import check_exist_or_remove, check_exist_or_mkdirs\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "def train(dataset, model, batch_size, lr, epoches, log_interval, save_along_training):\n",
    "    \"\"\"train implicit version of foldingnet\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    chamfer_distance_loss = ChamfersDistance()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n",
    "    model = model.train()\n",
    "\n",
    "    # enable distributed training\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    check_exist_or_remove(\"../log/train_loss_log.txt\")\n",
    "    check_exist_or_mkdirs(\"../log\")\n",
    "    # loss_log = open('../log/train_loss_log.txt', 'w+')\n",
    "\n",
    "    start = timer()\n",
    "    for ep in range(0, epoches):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            opt.zero_grad()\n",
    "            data = batch.to(device)\n",
    "            # print(data.shape)\n",
    "            #data = data.type(torch.cuda.FloatTensor)\n",
    "            points_pred = model(data)\n",
    "            loss = chamfer_distance_loss(data, points_pred)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % log_interval == log_interval - 1:\n",
    "                end = timer()\n",
    "                print('[%d, %5d] loss: %.6f elapsed time: %.2f' %\n",
    "                    (ep + 1, batch_idx + 1, running_loss / log_interval, timedelta(seconds=end-start).total_seconds()))\n",
    "                with open('../log/train_loss_log.txt', 'a+') as f:\n",
    "                    f.write('[{0:d}, {1:5d}] loss: {2:.6f}\\n'.format(ep + 1, batch_idx + 1, running_loss / log_interval))\n",
    "                running_loss = 0.0\n",
    "        if save_along_training:\n",
    "            torch.save(model.state_dict(), os.path.join('../model', 'ep_%d.pth' % ep))\n",
    "    if save_along_training:   # the last one\n",
    "        torch.save(model.state_dict(), os.path.join('../model', 'ep_%d.pth' % ep))\n",
    "    # loss_log.close()\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ROOT = \"../data/nyc/\"    # root path\n",
    "    ROOT = \"/home/bns332/foldingnet/Complex_Buildings\"\n",
    "    TRIAN_PATH = \"/home/bns332/foldingnet/train.txt\"\n",
    "    MLP_DIMS = (3,64,64,64,128,1024)\n",
    "    FC_DIMS = (1024, 512, 512)\n",
    "    GRID_DIMS = (45, 45)\n",
    "    # FOLDING1_DIMS = (521, 512, 512, 3)   # change the input feature of the first fc because now has 9 dims instead of 2\n",
    "    FOLDING1_DIMS = (514, 512, 512, 3)\n",
    "    FOLDING2_DIMS = (515, 512, 512, 3)\n",
    "    MLP_DOLASTRELU = False\n",
    "\n",
    "    check_exist_or_remove('../model')   # clean up old history\n",
    "    check_exist_or_mkdirs('../model')\n",
    "    kwargs = {\n",
    "        'lr': 0.0001,\n",
    "        # 330\n",
    "        'epoches': 3,\n",
    "        # 256\n",
    "        'batch_size':1,\n",
    "        'log_interval': 100,\n",
    "        'save_along_training': False\n",
    "    }\n",
    "\n",
    "    with open(TRIAN_PATH) as fp:\n",
    "        catelog = fp.readlines()\n",
    "    catelog = [x.strip() for x in catelog]\n",
    "    print(\"catelog done !\")\n",
    "    #import datasets\n",
    "    dataset = plyDataset(ROOT, catelog)\n",
    "    print(\"About to create model\")\n",
    "    # model = FoldingNetShapes(MLP_DIMS, FC_DIMS, FOLDING1_DIMS, FOLDING2_DIMS)\n",
    "    model = FoldingNetVanilla(MLP_DIMS, FC_DIMS, GRID_DIMS, FOLDING1_DIMS, FOLDING2_DIMS)\n",
    "    print(\"About to start training\")\n",
    "    train(dataset, model, **kwargs)\n",
    "    print(\"End training!!!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    catelog = [x.strip() for x in catelog]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3, 1])\n",
      "torch.Size([3, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "print(a.size())\n",
    "a = a.unsqueeze(2)\n",
    "print(a.size())\n",
    "b = a.expand(-1,-1,10)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected a Tensor of type torch.FloatTensor but found a type torch.cuda.FloatTensor for sequence element 1 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-dfbedfc2588f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#b = b.cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected a Tensor of type torch.FloatTensor but found a type torch.cuda.FloatTensor for sequence element 1 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor(3,3)\n",
    "print(a.dtype)\n",
    "b = a.cuda()\n",
    "print(b.dtype)\n",
    "#b = b.cpu()\n",
    "c = torch.cat((a,b),0)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4341307587942154240., -4833644430726529024., -4704204974102413312.],\n",
      "        [ 4507010312439857152.,  4442692455627751424.,  4499404990510530560.],\n",
      "        [ 4398392857266749440., -4713783919403597824.,  4485017880861081600.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.cuda.FloatTensor(3,3)\n",
    "b = torch.cuda.LongTensor(3,3)\n",
    "b = b.float()\n",
    "print(b+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
